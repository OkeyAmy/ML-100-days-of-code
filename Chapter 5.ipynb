{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a45bc8-78f7-43bf-9d72-a0bf71efd926",
   "metadata": {},
   "source": [
    "# Support Vector Machines(SVM)\n",
    "\n",
    "SVM is a very powerful tool capable of performing linear and non-linear classification, regression,and even outlier detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5766567-bb45-4ab2-97a0-78a29da88e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n",
      "Predicted target name ['setosa']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM Classification\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()\n",
    "\n",
    "X = iris.data[:,(2,3)] # petal length and petal width\n",
    "y = (iris['target'] == 2).astype('int')\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(loss='hinge', C=1, dual=True))\n",
    "])\n",
    "\n",
    "svm_clf.fit(X,y)\n",
    "pred = svm_clf.predict([[0.5,2]])\n",
    "print(\"Prediction: {}\".format(pred))\n",
    "print('Predicted target name {}'.format(iris['target_names'][pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a824c-86b1-476f-9ec5-a043d0e07d95",
   "metadata": {},
   "source": [
    "# The LinearSVC class regularizes the bias term, so you should center the training set first by subtracting its mean. This is automatic if you scale the data using the StandardScaler. Moreover, make sure you set the loss hyperparameter to \"hinge\", as it is not the default value. Finally, for better performance you should set the dual hyperparameter to False, unless there are more features than training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3c39be-6305-4b82-9cbd-6c537cef3982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR we could use SVC but it much slower when we have much training sets\n",
    "svc_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', SVC(C=1, kernel='linear'))\n",
    "])\n",
    "\n",
    "svc_clf.fit(X,y)\n",
    "svc_clf.predict([[1.5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbd20b9-d3b7-41b2-adb4-f23718b356dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "m = 150 \n",
    "C = 1\n",
    "sdg_clf = SGDClassifier(loss='hinge', alpha=1/(m*C))\n",
    "sdg_clf.fit(X,y)\n",
    "sdg_clf.predict([[1.5,2]])\n",
    "\n",
    "# This applies regular Stochastic Gradient Descent to train a linear SVM classifier.\n",
    "# It also handles large training set that can fit into the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034f512-81df-40fc-bc95-07c08fda897b",
   "metadata": {},
   "source": [
    "# Non Linear SVM Classification\n",
    "One approach to \n",
    "handling nonlinear datasets is to add more features, such as polynomial feature, in some cases this can result in a linearly separable dataset.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89715944-c8a1-4153-abbf-07e447d3baee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "X, y= make_moons()\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    ('polynomial', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=10, loss='hinge', dual=True))\n",
    "])\n",
    "\n",
    "polynomial_svm_clf.fit(X,y)\n",
    "polynomial_svm_clf.predict([[2e-1, 4e-8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650fc65c-1dad-41fd-a89d-3f6fa15a8d71",
   "metadata": {},
   "source": [
    "# Polynomial Kernel\n",
    "Adding polynomial features is simple to implement and can work great with all sorts \n",
    "of Machine Learning algorithms (not just SVMs), but at a low polynomial degree i \r\n",
    "cannot deal with very complex datasets, and with a high polynomial degree it creat s\r\n",
    "a huge number of features, making the model too slw.\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984f61e1-a5e8-42eb-9b52-abcbc4226a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "poly_kernal_svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='poly', C=1, degree=3, coef0=1))\n",
    "])\n",
    "\n",
    "poly_kernal_svm_clf.fit(X, y)\n",
    "poly_kernal_svm_clf.predict([[2e-1, 4e-8]])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5da321b-afbe-482c-b15f-cb6716a22a72",
   "metadata": {},
   "source": [
    "The hyperparameter \"coef0\" controls how much the model is influenced by high-degree polynomials versus low-degree polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61913df1-5e48-4390-8434-fc212ecf83cc",
   "metadata": {},
   "source": [
    "# Adding Similarity Features:  Gaussian RBF\n",
    "Another technique to tackle nonlinear problems is to add features computed using a similarity function that measures how much each instance resembles a particular landmark.\n",
    "\n",
    "Mathematically\n",
    "\n",
    "$\\phi_γ(X,ℓ)$ = $exp(-\\gamma||X - ℓ||^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485d0073-91d7-4c20-b820-9c0940235646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernal_svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='rbf', gamma=3, C=0.001))\n",
    "])\n",
    "rbf_kernal_svm_clf.fit(X,y)\n",
    "rbf_kernal_svm_clf.predict([[2e-1, 4e-8]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50f09972-eda3-4dc4-b11c-2468d2645445",
   "metadata": {},
   "source": [
    "Increasing gamma makes the bell-shape curve narrower, and as a result each instance’s range of influence is smaller: the decision boundary ends up being more irregular, wiggling around individual instances. Conversely, a small gamma value makes the bell-shaped curve wider, so instances have a larger range of influence, and the decision boundary ends up smoother. So gamma(γ) acts like a regularization hyperparameter: if your model is overfitting, you should reduce it, and if it is underfitting, you should increase it (similar to the C hyperparameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48040dd8-545e-4bd8-b6fc-165696213f2f",
   "metadata": {},
   "source": [
    "# Computational Complexity\r\n",
    "\n",
    "| Class | Time Complexity | Out-of-core support | Scaling required | Kernel trick |\n",
    "|:---------|:--------:|---------:| ---------:| ---------:|\n",
    "|  LinearSVC  |  $O(m * n)$  |  No   |  Yes   |  No   |\n",
    "|  SDGClassifier  |   $O(m * n)$   | Yes   |  Yes  | No |\n",
    "|  SVC  |  $O(m^2 * n)$ to $O (m^3 * n)$    |  No   |   Yes   |  Yes   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df791b2-5d27-4074-8ba3-08fb70abe2aa",
   "metadata": {},
   "source": [
    "# SVM Regression\n",
    "The SVM algorithm is quite versatile: not only does it support linear and nonlinear classification, but it also supports linear and nonlinear regression. The width of the street is controlled by a hyperparameter $ϵ$(which controls the margin). Higher value of $ϵ$ leads to more space margin while lower $ϵ$ leads to smaller margin. Adding more training instances within the margin does not affect the model’s predictions; thus, the model is said to be  $ϵ$-insensitive\n",
    "\n",
    "_It is known as epsilon._ \n",
    "\n",
    "SVMs can also be used for outlier detection; see Scikit-Learn’s doc\n",
    "umentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de8ac74f-8fa5-4f0b-bd4d-8d85283181ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR, SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de742f3-80fa-445b-b3bf-75043228fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVR(epsilon=1.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVR</label><div class=\"sk-toggleable__content\"><pre>LinearSVR(epsilon=1.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d4010d3-4cc1-472b-b8ea-eceba15494d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=100, degree=2, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=100, degree=2, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=100, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_poly_reg = SVR(degree=2, kernel='poly', C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b49357-98f3-4405-ba5d-b829360bac24",
   "metadata": {},
   "source": [
    "# Kernel\n",
    "A kernel is a function capable of computing the dot product based only on the original vectors a and b, without having to compute (or even to know about) the transformation.\n",
    "\n",
    "Common kernels\n",
    "\n",
    "Linear: $K(a,b)$ = $a^Tb$\n",
    "\n",
    "Polynomial: $K(a,b)$ = $(\\gamma a^Tb+r)^d$\n",
    "\n",
    "Gaussian RBF: $K(a,b)$ = $exp(-\\gamma||a - b||^2)$\n",
    "\n",
    "Sigmoid: $K(a,b)$ = $tanh(\\gamma a^T b + r)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ca27d-43d1-486a-a198-275be4cdebea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
