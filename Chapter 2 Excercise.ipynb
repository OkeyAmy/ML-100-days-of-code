{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Try a Support Vector Machine regressor (sklearn.svm.SVR), with various hyperparameters such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Donâ€™t worry about what these hyperparameters mean for now.\n",
    "\n",
    "How does the best SVR predictor perform?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d37f00ab34c3e755"
  },
  {
   "cell_type": "markdown",
   "source": [
    "My dataset set has alredy been splitted for me into train set and test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a106074612f879ab"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "# Libary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T01:31:36.328796100Z",
     "start_time": "2024-07-18T01:31:36.318786500Z"
    }
   },
   "id": "8690ecee96fc63bb"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import my dataset\n",
    "train_set = pd.read_csv(\"C:/Users/HP/Desktop/ML with scikit-learn, keras and tensorflow/Data/Titanic/train.csv\")\n",
    "test_set = pd.read_csv(\"C:/Users/HP/Desktop/ML with scikit-learn, keras and tensorflow/Data/Titanic/test.csv\")\n",
    "label_set = pd.read_csv(\"C:/Users/HP/Desktop/ML with scikit-learn, keras and tensorflow/Data/Titanic/gender_submission.csv\")\n",
    "# train_set.head(7)\n",
    "test_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T20:04:16.139057900Z",
     "start_time": "2024-07-17T20:04:15.993594400Z"
    }
   },
   "id": "97274ec6e4f6848c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean my Train set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c83e4cc34ea5703"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN\n",
    "train_set.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T19:27:25.721960100Z",
     "start_time": "2024-07-17T19:27:25.607543100Z"
    }
   },
   "id": "b720b47f3c48e508"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Embarked\nS    644\nC    168\nQ     77\nName: count, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to drop\n",
    "drop_columns = ['PassengerId', 'Cabin', 'Name', 'Ticket']\n",
    "\n",
    "# Drop column\n",
    "drop_set = train_set.drop(drop_columns, axis=1)\n",
    "drop_set['Embarked'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T19:27:26.398659Z",
     "start_time": "2024-07-17T19:27:25.660961100Z"
    }
   },
   "id": "214888605fbb5b85"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex  Embarked\n0       0.0     3.0  22.0    1.0    0.0   7.2500  1.0       2.0\n1       1.0     1.0  38.0    1.0    0.0  71.2833  0.0       0.0\n2       1.0     3.0  26.0    0.0    0.0   7.9250  0.0       2.0\n3       1.0     1.0  35.0    1.0    0.0  53.1000  0.0       2.0\n4       0.0     3.0  35.0    0.0    0.0   8.0500  1.0       2.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.2500</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>38.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>71.2833</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>26.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.9250</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>35.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>53.1000</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>35.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0500</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List categorical variable and numerical varible\n",
    "cat_set = ['Sex', 'Embarked']\n",
    "num_set = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "# Set my numerical dataset\n",
    "drop_set_num = drop_set[num_set]\n",
    "drop_set_num_attribs = list(drop_set_num)\n",
    "drop_set_num_attribs\n",
    "\n",
    "# Set my categorical variable\n",
    "drop_set_cat =drop_set[cat_set]\n",
    "drop_set_cat_attribs = list(drop_set_cat)\n",
    "#Create a list of cat dataframe\n",
    "# drop_set_cat_attribs = list(drop_set_cat_trans)\n",
    "# drop_set_cat_attribs\n",
    "\n",
    "# Clean my cat Nan rows and convert to dataframe\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('ord', OrdinalEncoder())\n",
    "])\n",
    "# imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "drop_set_cat_trans = pipeline.fit_transform(drop_set_cat)\n",
    "drop_set_cat_trans = pd.DataFrame(drop_set_cat_trans, columns=['Sex', 'Embarked'])\n",
    "\n",
    "\n",
    "# # Deal with NaN in Age column\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), drop_set_num_attribs),\n",
    "    ('ord', pipeline, drop_set_cat_attribs),\n",
    "])\n",
    "\n",
    "\n",
    "# Transform my dataset\n",
    "train_set_prepared = full_pipeline.fit_transform(drop_set)\n",
    "# Create a column name for my prepared datset\n",
    "train_set_prepared = pd.DataFrame(train_set_prepared, columns= ['Survived', 'Pclass', 'Age', 'SibSp','Parch', 'Fare', 'Sex','Embarked'])\n",
    "\n",
    "train_set_prepared.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T19:51:56.902812100Z",
     "start_time": "2024-07-17T19:51:56.433810900Z"
    }
   },
   "id": "2d9e04343a737195"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "y = train_set_prepared['Survived']\n",
    "X = train_set_prepared.drop('Survived', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T19:55:41.781309800Z",
     "start_time": "2024-07-17T19:55:41.576897600Z"
    }
   },
   "id": "ade6abeb9c8f65d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean my Test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32151fa741c33058"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T20:06:22.530036200Z",
     "start_time": "2024-07-17T20:06:22.497968100Z"
    }
   },
   "id": "b824b862bf9bb8a9"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "drop_columns = ['PassengerId', 'Cabin', 'Name', 'Ticket']\n",
    "\n",
    "# Drop column\n",
    "t_drop_set = test_set.drop(drop_columns, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T20:10:28.859903200Z",
     "start_time": "2024-07-17T20:10:28.819706700Z"
    }
   },
   "id": "8ea747e2b378efb9"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "   Pclass   Age  SibSp  Parch     Fare  Sex  Embarked\n0     3.0  34.5    0.0    0.0   7.8292  1.0       1.0\n1     3.0  47.0    1.0    0.0   7.0000  0.0       2.0\n2     2.0  62.0    0.0    0.0   9.6875  1.0       1.0\n3     3.0  27.0    0.0    0.0   8.6625  1.0       2.0\n4     3.0  22.0    1.0    1.0  12.2875  0.0       2.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.0</td>\n      <td>34.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.8292</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>47.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0000</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>62.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.6875</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.6625</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>12.2875</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List categorical variable and numerical varible\n",
    "cat_set = ['Sex', 'Embarked']\n",
    "num_set = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "# Set my numerical dataset\n",
    "t_drop_set_num = t_drop_set[num_set]\n",
    "t_drop_set_num_attribs = list(t_drop_set_num)\n",
    "t_drop_set_num_attribs\n",
    "\n",
    "# Set my categorical variable\n",
    "t_drop_set_cat =t_drop_set[cat_set]\n",
    "t_drop_set_cat_attribs = list(drop_set_cat)\n",
    "#Create a list of cat dataframe\n",
    "# drop_set_cat_attribs = list(drop_set_cat_trans)\n",
    "# drop_set_cat_attribs\n",
    "\n",
    "# Clean my cat Nan rows and convert to dataframe\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('ord', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "t_drop_set_cat_trans = pipeline.fit_transform(t_drop_set_cat)\n",
    "t_drop_set_cat_trans = pd.DataFrame(t_drop_set_cat_trans, columns=['Sex', 'Embarked'])\n",
    "\n",
    "\n",
    "# # Deal with NaN in Age column\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), t_drop_set_num_attribs),\n",
    "    ('ord', pipeline, t_drop_set_cat_attribs),\n",
    "])\n",
    "\n",
    "\n",
    "# Transform my dataset\n",
    "test_set_prepared = full_pipeline.fit_transform(t_drop_set)\n",
    "# Create a column name for my prepared datset\n",
    "test_set_prepared = pd.DataFrame(test_set_prepared, columns= ['Pclass', 'Age', 'SibSp','Parch', 'Fare', 'Sex','Embarked'])\n",
    "\n",
    "test_set_prepared.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T20:15:04.174610900Z",
     "start_time": "2024-07-17T20:15:04.080258800Z"
    }
   },
   "id": "cd41cf19f90d5aa0"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[82], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m svr_linear \u001B[38;5;241m=\u001B[39m SVR(kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m, C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m svr_fit \u001B[38;5;241m=\u001B[39m svr_linear\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[1;32m----> 6\u001B[0m \u001B[43maccuracy_score\u001B[49m(svr_fit)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Load the model\n",
    "svr_linear = SVR(kernel='linear', C=1, gamma='auto')\n",
    "\n",
    "svr_fit = svr_linear.fit(X, y)\n",
    "\n",
    "test_set\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T23:18:14.008215Z",
     "start_time": "2024-07-17T23:17:24.260247700Z"
    }
   },
   "id": "ab988eeffaabeb21"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "y_pred = svr_fit.predict(test_set_prepared)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T23:05:25.370414500Z",
     "start_time": "2024-07-17T23:05:24.451509800Z"
    }
   },
   "id": "6fe5de28dcf5c7ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try using RandomizedSearchCV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6211ddace189491"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.416427640638861 {'C': 25.715714285714288}\n",
      "13.786637650434162 {'kernel': 'sigmoid'}\n",
      "0.43270654661080693 {'C': 25.103673469387758}\n",
      "0.4157601403708816 {'C': 28.77591836734694}\n",
      "0.4681967039179341 {'C': 0.01}\n",
      "0.4249860153120484 {'C': 15.923061224489796}\n",
      "0.42071176663989635 {'C': 23.879591836734697}\n",
      "0.41875758654868583 {'C': 26.32775510204082}\n",
      "0.4178031022071908 {'C': 28.16387755102041}\n",
      "0.4472214686441989 {'gamma': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "#Set my paramter grid\n",
    "param_grid = [\n",
    "    {'C': np.linspace(0.01, 30, 50)},\n",
    "    {'epsilon': [0.01, 0.1, 1]},\n",
    "    {'gamma': ['scale', 'auto']},\n",
    "    {'kernel': ['rbf','linear',\"poly\",\"sigmoid\"]}\n",
    "]\n",
    "\n",
    "# Load my model\n",
    "svr_rbf = SVR()\n",
    "\n",
    "# Finding the best parameters\n",
    "grid_search = RandomizedSearchCV(svr_rbf, param_grid, cv=5, \n",
    "                                 scoring='neg_mean_squared_error', \n",
    "                                 return_train_score=True)\n",
    "# Fit my model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Find the best estimator and parameter\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_param = grid_search.best_params_\n",
    "\n",
    "#Evaluation scores\n",
    "cvres = grid_search.cv_results_\n",
    "\n",
    "for mean_scores, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_scores),params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T00:31:10.019594400Z",
     "start_time": "2024-07-18T00:31:05.051528400Z"
    }
   },
   "id": "7081d2bba13b150"
  },
  {
   "cell_type": "markdown",
   "source": [
    "My best paramter will be 0.4157601403708816 {'C': 28.77591836734694} because it a low rmse in it test score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b86048fac8ca9a03"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.01542174, 0.03455791, 0.01507432, 0.00151585, 0.02695813,\n       0.12912836, 0.00126251])"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the feature importance\n",
    "feature_importance = permutation_importance(grid_search,X, y)\n",
    "feature_importance_value = feature_importance['importances_mean']\n",
    "feature_importance_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T01:13:15.751829800Z",
     "start_time": "2024-07-18T01:13:12.537772900Z"
    }
   },
   "id": "c565beb132e3bd3f"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       250\n",
      "           1       0.96      0.87      0.91       168\n",
      "\n",
      "    accuracy                           0.93       418\n",
      "   macro avg       0.94      0.92      0.93       418\n",
      "weighted avg       0.93      0.93      0.93       418\n"
     ]
    }
   ],
   "source": [
    "#Predicting Surival Rate\n",
    "y_pred = grid_search.predict(test_set_prepared)\n",
    "\n",
    "# Converting predicted value to binary\n",
    "binary_prediction = (y_pred >= 0.5).astype(int) # I got just this code from AI\n",
    "\n",
    "# Print my accurcacy score\n",
    "print(classification_report(binary_prediction, label_set['Survived']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T01:32:47.183942900Z",
     "start_time": "2024-07-18T01:32:47.116106100Z"
    }
   },
   "id": "fef2da5cce6e428e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
